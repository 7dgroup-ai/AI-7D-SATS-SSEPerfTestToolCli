# 7DGroup SSE 流式输出性能测试工具指标计算方法

本文档详细说明 7DGroup SSE 流式输出性能测试工具中所有指标趋势图的计算方法。

## 一、时间基准说明

所有时间序列图表使用统一的时间基准：

```python
start_time = min((r.get("request_start_time", 0) for r in results_list), default=0)
```

- **时间基准**：第一个请求的开始时间（毫秒）
- **相对时间计算**：`relative_time = (timestamp - start_time) / 1000.0`（转换为秒）
- **目的**：确保所有图表的时间轴对齐，便于对比分析

---

## 二、请求级别指标（单个请求的性能指标）

这些指标反映每个请求的性能特征，数据来源为 `results_list` 中每个请求的统计信息。

### 2.1 TTFT (Time To First Token) 趋势

**指标含义**：从请求开始到收到第一个包含 answer 的 token 的时间。

**计算方法**：
```python
ttft = first_token_time - request_start_time
```

**详细步骤**：
1. 记录请求开始时间：`request_start_time = time.time() * 1000`（毫秒）
2. 当收到第一个包含 `answer` 字段的 SSE 数据块时，记录时间：`first_token_time = time.time() * 1000`（毫秒）
3. 计算差值：`ttft = first_token_time - request_start_time`（毫秒）

**数据来源**：
- 每个成功请求的 `ttft` 字段
- 时间序列：`request_timeline` 中每个请求的 `ttft` 值

**图表显示**：
- X 轴：相对时间（秒），从测试开始时间计算
- Y 轴：TTFT（毫秒）
- 数据点：每个请求一个数据点

---

### 2.2 TPOT (Time Per Output Token) 趋势

**指标含义**：每个输出 token 的平均时间。

**计算方法**：
```python
if token_count > 1:
    tpot = (last_token_time - first_token_time) / (token_count - 1)
else:
    tpot = 0  # 只有一个token时，TPOT为0
```

**详细步骤**：
1. 记录每个 token 的时间戳：在接收每个数据块时，将当前时间戳添加到 `token_times` 列表
2. 获取第一个和最后一个 token 的时间戳：
   - `first_token_time = token_times[0]`
   - `last_token_time = token_times[-1]`
3. 计算总时间：`total_token_time = last_token_time - first_token_time`（毫秒）
4. 计算 TPOT：`tpot = total_token_time / (token_count - 1)`（毫秒/token）

**说明**：
- 使用 `(token_count - 1)` 是因为计算的是 token 之间的间隔数
- 例如：3 个 token 有 2 个间隔

**数据来源**：
- 每个成功请求的 `tpot` 字段
- 时间序列：`request_timeline` 中每个请求的 `tpot` 值

**图表显示**：
- X 轴：相对时间（秒）
- Y 轴：TPOT（毫秒/token）
- 数据点：每个请求一个数据点

---

### 2.3 TTFB (Time To First Byte) 趋势

**指标含义**：从请求开始到收到第一个字节的时间。

**计算方法**：
```python
ttfb = first_byte_time - request_start_time
```

**详细步骤**：
1. 记录请求开始时间：`request_start_time = time.time() * 1000`（毫秒）
2. 当第一次从响应流中读取到数据时，记录时间：`first_byte_time = time.time() * 1000`（毫秒）
3. 计算差值：`ttfb = first_byte_time - request_start_time`（毫秒）

**数据来源**：
- 每个成功请求的 `ttfb` 字段
- 时间序列：`request_timeline` 中每个请求的 `ttfb` 值

**图表显示**：
- X 轴：相对时间（秒）
- Y 轴：TTFB（毫秒）
- 数据点：每个请求一个数据点

---

### 2.4 吞吐量 (Tokens/s) 趋势

**指标含义**：单个请求的 token 生成速度。

**计算方法**：
```python
if streaming_duration > 0 and token_count > 0:
    throughput = (token_count / streaming_duration) * 1000  # tokens/秒
else:
    throughput = 0
```

**详细步骤**：
1. 计算流式传输时长：`streaming_duration = last_byte_time - first_byte_time`（毫秒）
2. 统计 token 数量：`token_count`（通过 `_estimate_tokens()` 方法估算）
3. 计算吞吐量：`throughput = (token_count / streaming_duration) * 1000`（tokens/秒）

**Token 估算方法**：
```python
def _estimate_tokens(text: str) -> int:
    chinese_chars = sum(1 for c in text if '\u4e00' <= c <= '\u9fff')
    english_words = len([w for w in text.split() if w.isalpha()])
    return max(1, chinese_chars + english_words)
```

**数据来源**：
- 每个成功请求的 `throughput` 字段
- 时间序列：`request_timeline` 中每个请求的 `throughput` 值

**图表显示**：
- X 轴：相对时间（秒）
- Y 轴：吞吐量（tokens/s）
- 数据点：每个请求一个数据点

---

### 2.5 响应时间趋势

**指标含义**：从请求开始到请求结束的总时间。

**计算方法**：
```python
total_response_time = request_end_time - request_start_time
```

**详细步骤**：
1. 记录请求开始时间：`request_start_time = time.time() * 1000`（毫秒）
2. 当响应流完全接收完毕时，记录时间：`request_end_time = time.time() * 1000`（毫秒）
3. 计算总响应时间：`total_response_time = request_end_time - request_start_time`（毫秒）

**数据来源**：
- 每个成功请求的 `total_response_time` 字段
- 时间序列：`request_timeline` 中每个请求的 `response_time` 值

**图表显示**：
- X 轴：相对时间（秒）
- Y 轴：响应时间（毫秒）
- 数据点：每个请求一个数据点

---

### 2.6 Token 数量趋势

**指标含义**：每个请求生成的 token 总数。

**计算方法**：
```python
token_count = sum(_estimate_tokens(chunk) for chunk in answer_chunks)
```

**详细步骤**：
1. 在接收每个 SSE 数据块时，提取 `answer` 字段
2. 对每个数据块调用 `_estimate_tokens()` 估算 token 数
3. 累加所有数据块的 token 数：`token_count += chunk_tokens`

**数据来源**：
- 每个成功请求的 `token_count` 字段
- 时间序列：`request_timeline` 中每个请求的 `token_count` 值

**图表显示**：
- X 轴：相对时间（秒）
- Y 轴：Token 数量
- 数据点：每个请求一个数据点

---

## 三、系统级别指标（系统整体的性能指标）

这些指标反映系统整体的性能特征，会随线程数变化，数据来源为 `shared_stats["time_series"]`（每秒汇总一次）。

### 3.1 活跃线程数趋势

**指标含义**：每个时间点的活跃线程数量。

**计算方法**：

**方法一（从 time_series 获取）**：
```python
active_threads = len(shared_stats["thread_stats"])
total_threads = shared_stats.get("total_threads", active_threads)
```

**方法二（从 results_list 推断）**：
```python
# 创建时间窗口，统计每个时间点的活跃线程数
time_windows = {}
for r in results_list:
    req_start = r.get("request_start_time", 0)
    req_end = r.get("request_end_time", req_start)
    thread_id = r.get("thread_id", 0)
    start_sec = (req_start - start_time) / 1000.0
    end_sec = (req_end - start_time) / 1000.0
    # 在时间窗口中标记线程活跃
    for t in range(int(start_sec), int(end_sec) + 1):
        if t not in time_windows:
            time_windows[t] = set()
        time_windows[t].add(thread_id)

# 转换为时间序列
for t in sorted(time_windows.keys()):
    active_threads = len(time_windows[t])
```

**数据来源**：
- `shared_stats["time_series"]` 中每个时间点的 `active_threads` 和 `total_threads`
- 如果没有 time_series，则从 `results_list` 推断

**图表显示**：
- X 轴：相对时间（秒）
- Y 轴：线程数
- 数据点：每秒一个数据点（或从请求推断的时间点）
- 显示两条线：
  - 活跃线程数（绿色实线）
  - 总线程数（红色虚线）

---

### 3.2 系统总吞吐量 (Tokens/s) 趋势

**指标含义**：系统整体每秒生成的 token 总数。

**计算方法**：
```python
# 从 time_series 获取（每秒汇总）
tokens_per_second = (total_tokens * 1000) / elapsed_ms
```

**详细步骤**（在 `aggregate_stats` 函数中每秒计算一次）：
1. 获取所有线程的统计信息：`thread_stats = list(shared_stats["thread_stats"].values())`
2. 计算总 token 数：`total_tokens = sum(s.get("tokens", 0) for s in thread_stats)`
3. 计算时间范围：
   - `earliest_start = min(s.get("start_time") for s in thread_stats)`
   - `latest_update = max(s.get("last_update") for s in thread_stats)`
   - `elapsed_ms = max(latest_update - earliest_start, 1)`
4. 计算系统总吞吐量：`tokens_per_second = (total_tokens * 1000) / elapsed_ms`（tokens/秒）

**注意**：系统总吞吐量是系统级别的指标，直接使用所有线程的总 token 数除以总时间，不需要按线程分组计算。

**数据来源**：
- `shared_stats["time_series"]` 中每个时间点的 `tokens_per_second` 值
- 如果没有 time_series，则从 `results_list` 计算：
  ```python
  total_tokens = sum(r.get("token_count", 0) for r in results_list)
  total_duration = (actual_end_time - actual_start_time) / 1000.0  # 秒
  system_throughput = total_tokens / total_duration  # tokens/s
  ```

**图表显示**：
- X 轴：相对时间（秒）
- Y 轴：系统总吞吐量（tokens/s）
- 数据点：每秒一个数据点

**说明**：
- 这个指标会随线程数增加而增加（如果系统未达到上限）
- 反映了系统的整体处理能力

---

### 3.3 系统平均响应时间 (ms) 趋势

**指标含义**：系统整体的平均响应时间。

**计算方法**：
```python
# 从 time_series 获取（每秒汇总）
avg_response_time = elapsed_ms / max(total_chunks, 1)
```

**详细步骤**（在 `aggregate_stats` 函数中每秒计算一次）：
1. **按线程计算**：从 `shared_stats["thread_requests"]` 获取每个线程的请求数据
2. **计算每个线程的平均响应时间**：
   ```python
   for thread_id, requests in thread_requests.items():
       if requests:
           thread_avg_response_time = sum(r.get("total_response_time", 0) for r in requests) / len(requests)
   ```
3. **汇总所有线程的指标（加权平均）**：
   ```python
   total_request_count = sum(m.get("request_count", 0) for m in thread_metrics.values())
   avg_response_time = sum(m.get("avg_response_time", 0) * m.get("request_count", 0) for m in thread_metrics.values()) / total_request_count
   ```

**注意**：系统平均响应时间需要按线程分组计算后再汇总，确保准确性。

**数据来源**：
- `shared_stats["time_series"]` 中每个时间点的 `avg_response_time` 值
- 如果没有 time_series，则从 `results_list` 计算：
  ```python
  total_time = sum(r.get("total_response_time", 0) for r in results_list)
  avg_time = total_time / len(successful_results)  # 毫秒
  ```

**图表显示**：
- X 轴：相对时间（秒）
- Y 轴：系统平均响应时间（毫秒）
- 数据点：每秒一个数据点

**说明**：
- 这个指标会随线程数增加而增加（如果系统达到负载上限）
- 反映了系统在压力下的响应速度

---

### 3.4 系统平均 TPOT (ms/token) 趋势

**指标含义**：系统整体的平均每 token 生成时间。

**计算方法**：
```python
# 从 time_series 获取（每秒汇总）
# 当没有已完成的请求时，使用备用计算公式
if total_tokens > 1:
    tpot = elapsed_ms / (total_tokens - 1)
else:
    tpot = 0  # 只有0或1个token时，TPOT为0
```

**详细步骤**（在 `aggregate_stats` 函数中每秒计算一次）：
1. **按线程计算**：从 `shared_stats["thread_requests"]` 获取每个线程的请求数据
2. **计算每个线程的平均 TPOT**：
   ```python
   for thread_id, requests in thread_requests.items():
       if requests:
           thread_avg_tpot = sum(r.get("tpot", 0) for r in requests) / len(requests)
   ```
3. **汇总所有线程的指标（加权平均）**：
   ```python
   total_request_count = sum(m.get("request_count", 0) for m in thread_metrics.values())
   avg_tpot = sum(m.get("avg_tpot", 0) * m.get("request_count", 0) for m in thread_metrics.values()) / total_request_count
   ```

**注意**：系统平均 TPOT 需要按线程分组计算后再汇总，确保准确性。

**数据来源**：
- `shared_stats["time_series"]` 中每个时间点的 `tpot` 值
- 如果没有 time_series，则从 `results_list` 计算：
  ```python
  avg_tpot = sum(r.get("tpot", 0) for r in successful_results) / len(successful_results)
  ```

**图表显示**：
- X 轴：相对时间（秒）
- Y 轴：系统平均 TPOT（毫秒/token）
- 数据点：每秒一个数据点

**说明**：
- 这个指标会随线程数增加而增加（如果系统达到负载上限）
- 反映了系统在压力下的 token 生成速度

---

### 3.5 总请求数趋势

**指标含义**：累积的总请求数。

**计算方法**：
```python
total_requests = shared_stats.get("requests", 0)
```

**详细步骤**：
1. 在 `run_test_thread` 函数中，每次请求完成后更新：
   ```python
   with shared_stats["lock"]:
       shared_stats["requests"] += 1
   ```
2. 在 `aggregate_stats` 函数中每秒读取：`total_reqs = shared_stats.get("requests", 0)`

**数据来源**：
- `shared_stats["time_series"]` 中每个时间点的 `total_requests` 值
- 如果没有 time_series，则从 `results_list` 计算：`total_requests = len(results_list)`

**图表显示**：
- X 轴：相对时间（秒）
- Y 轴：总请求数
- 数据点：每秒一个数据点
- 趋势：单调递增

**说明**：
- 这个指标显示测试过程中请求的累积数量
- 可以用于评估测试的进度和请求速率

---

## 四、数据汇总统计

报告中的汇总统计表显示所有指标的平均值、最小值和最大值。

### 4.1 平均值计算（按线程分组后汇总）

**重要**：所有指标的计算都遵循"先按线程计算，再汇总"的原则，确保多线程测试时指标计算的准确性。

**计算步骤**：

1. **按线程ID分组**：
```python
thread_results = {}
for r in results_list:
    thread_id = r.get("thread_id", 0)
    if thread_id not in thread_results:
        thread_results[thread_id] = []
    thread_results[thread_id].append(r)
```

2. **计算每个线程的平均指标**：
```python
thread_metrics = {}
for thread_id, thread_reqs in thread_results.items():
    thread_successful = [r for r in thread_reqs if not r.get("error")]
    if thread_successful:
        thread_metrics[thread_id] = {
            "avg_ttft": sum(r.get("ttft", 0) for r in thread_successful) / len(thread_successful),
            "avg_tpot": sum(r.get("tpot", 0) for r in thread_successful) / len(thread_successful),
            "avg_ttfb": sum(r.get("ttfb", 0) for r in thread_successful) / len(thread_successful),
            "avg_throughput": sum(r.get("throughput", 0) for r in thread_successful) / len(thread_successful),
            "avg_response_time": sum(r.get("total_response_time", 0) for r in thread_successful) / len(thread_successful),
            "request_count": len(thread_successful)
        }
```

3. **汇总所有线程的指标（加权平均）**：
```python
total_request_count = sum(m.get("request_count", 0) for m in thread_metrics.values())
if total_request_count > 0:
    # 加权平均，权重为每个线程的请求数
    avg_ttft = sum(m.get("avg_ttft", 0) * m.get("request_count", 0) for m in thread_metrics.values()) / total_request_count
    avg_tpot = sum(m.get("avg_tpot", 0) * m.get("request_count", 0) for m in thread_metrics.values()) / total_request_count
    avg_ttfb = sum(m.get("avg_ttfb", 0) * m.get("request_count", 0) for m in thread_metrics.values()) / total_request_count
    avg_throughput = sum(m.get("avg_throughput", 0) * m.get("request_count", 0) for m in thread_metrics.values()) / total_request_count
    avg_time = sum(m.get("avg_response_time", 0) * m.get("request_count", 0) for m in thread_metrics.values()) / total_request_count
```

**为什么需要按线程分组计算？**

- **准确性**：不同线程可能有不同的性能特征，按线程分组可以更准确地反映每个线程的性能
- **公平性**：如果某个线程的请求数远多于其他线程，直接平均会导致结果偏向该线程
- **可分析性**：可以识别出性能异常的线程

**示例**：
- 线程1：10个请求，平均TTFT = 100ms
- 线程2：5个请求，平均TTFT = 200ms
- **错误计算**：直接平均 = (100 + 200) / 2 = 150ms
- **正确计算**：加权平均 = (100 * 10 + 200 * 5) / 15 = 133.33ms

### 4.2 最小值和最大值计算

```python
min_ttft = min((r.get('ttft', 0) for r in successful_results), default=0)
max_ttft = max((r.get('ttft', 0) for r in successful_results), default=0)
# 其他指标类似
```

---

## 五、时间序列数据准备

### 5.1 请求级别时间序列（request_timeline）

```python
request_timeline = []
start_time = min((r.get("request_start_time", 0) for r in results_list), default=0)
for r in sorted(results_list, key=lambda x: x.get("request_start_time", 0)):
    if not r.get("error"):
        relative_time = (r.get("request_start_time", 0) - start_time) / 1000.0
        request_timeline.append({
            "time": relative_time,
            "ttft": r.get("ttft", 0),
            "tpot": r.get("tpot", 0),
            "ttfb": r.get("ttfb", 0),
            "throughput": r.get("throughput", 0),
            "token_count": r.get("token_count", 0),
            "response_time": r.get("total_response_time", 0)
        })
```

### 5.2 系统级别时间序列（system_timeline）

```python
system_timeline = []
if shared_stats and "time_series" in shared_stats:
    time_series = shared_stats["time_series"]
    for ts in time_series:
        timestamp = float(ts.get("timestamp", 0))
        relative_time = (timestamp - start_time) / 1000.0
        if relative_time >= 0:
            system_timeline.append({
                "time": relative_time,
                "system_throughput": ts.get("tokens_per_second", 0),
                "system_avg_response_time": ts.get("avg_response_time", 0),
                "system_tpot": ts.get("tpot", 0),
                "total_requests": ts.get("total_requests", 0),
                "total_tokens": ts.get("total_tokens", 0),
                "success_rate": ts.get("success_rate", 0)
            })
```

---

## 六、关键说明

### 6.1 时间单位

- **时间戳**：毫秒（`time.time() * 1000`）
- **时间差**：毫秒
- **图表显示**：秒（通过除以 1000 转换）

### 6.2 数据粒度

- **请求级别指标**：每个请求一个数据点
- **系统级别指标**：每秒一个数据点（由 `aggregate_stats` 函数每秒汇总一次）

### 6.3 时间对齐

所有图表使用相同的时间基准（`start_time`），确保：
- 时间轴对齐
- 可以对比不同指标在同一时间点的值
- 可以分析线程数变化对其他指标的影响

### 6.4 指标分类

- **请求级别指标**：反映单个请求的性能，不会随线程数明显变化
- **系统级别指标**：反映系统整体性能，会随线程数变化，用于评估压力测试效果

### 6.5 按线程分组计算的重要性

**所有指标的计算都遵循"先按线程计算，再汇总"的原则**：

1. **准确性**：不同线程可能有不同的性能特征（网络延迟、服务器负载等），按线程分组可以更准确地反映每个线程的真实性能
2. **公平性**：如果某个线程的请求数远多于其他线程，直接平均会导致结果偏向该线程，加权平均可以避免这个问题
3. **可分析性**：可以识别出性能异常的线程，便于问题定位

**计算流程**：
```
1. 按线程ID分组所有请求
2. 计算每个线程的平均指标（TTFT、TPOT、TTFB、吞吐量、响应时间等）
3. 使用加权平均汇总所有线程的指标（权重为每个线程的请求数）
```

**示例**：
- 线程1：10个请求，平均TTFT = 100ms
- 线程2：5个请求，平均TTFT = 200ms
- **错误计算**（直接平均）：(100 + 200) / 2 = 150ms
- **正确计算**（加权平均）：(100 × 10 + 200 × 5) / 15 = 133.33ms

---

## 七、参考代码位置

- **请求级别指标计算**：`tester.py` 中的 `_calculate_metrics()` 方法
- **系统级别指标计算**：`test_runner.py` 中的 `aggregate_stats()` 函数
- **时间序列数据准备**：`report_generator.py` 中的 `generate_html_report()` 函数
- **Token 估算**：`tester.py` 中的 `_estimate_tokens()` 方法

---


