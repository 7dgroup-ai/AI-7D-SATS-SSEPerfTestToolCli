# ä»é›¶ç¼–å†™ AI å¤§æ¨¡å‹å‹æµ‹å·¥å…·æ•™ç¨‹

æœ¬æ•™ç¨‹å°†å¸¦ä½ ä»é›¶å¼€å§‹ï¼Œé€æ­¥æ„å»ºä¸€ä¸ªåŠŸèƒ½å®Œæ•´çš„ AI å¤§æ¨¡å‹æµå¼è¾“å‡ºæ€§èƒ½æµ‹è¯•å·¥å…·ã€‚æˆ‘ä»¬å°†ä»¥ SSE æµå¼è¾“å‡ºæµ‹è¯•è„šæœ¬ä¸ºä¾‹ï¼Œè¯¦ç»†è®²è§£æ¯ä¸ªæ­¥éª¤å’Œå…³é”®æŠ€æœ¯ç‚¹ã€‚

## ç›®å½•

1. [é¡¹ç›®æ¦‚è¿°](#é¡¹ç›®æ¦‚è¿°)
2. [æŠ€æœ¯æ ˆé€‰æ‹©](#æŠ€æœ¯æ ˆé€‰æ‹©)
3. [æ¶æ„è®¾è®¡](#æ¶æ„è®¾è®¡)
4. [é€æ­¥å®ç°](#é€æ­¥å®ç°)
5. [å…³é”®æŠ€æœ¯è¯¦è§£](#å…³é”®æŠ€æœ¯è¯¦è§£)
6. [æµ‹è¯•ä¸ä¼˜åŒ–](#æµ‹è¯•ä¸ä¼˜åŒ–)
7. [æ‰©å±•åŠŸèƒ½](#æ‰©å±•åŠŸèƒ½)
8. [æœ€ä½³å®è·µ](#æœ€ä½³å®è·µ)

---

## é¡¹ç›®æ¦‚è¿°

### ç›®æ ‡

æ„å»ºä¸€ä¸ª AI å¤§æ¨¡å‹æµå¼è¾“å‡ºæ€§èƒ½æµ‹è¯•å·¥å…·ï¼Œèƒ½å¤Ÿï¼š

- æµ‹è¯•æµå¼ API çš„æ€§èƒ½
- è®¡ç®—å…³é”®æ€§èƒ½æŒ‡æ ‡ï¼ˆTTFTã€TPOTã€TTFB ç­‰ï¼‰
- æ”¯æŒå¤šçº¿ç¨‹å¹¶å‘æµ‹è¯•
- æ”¯æŒå‚æ•°åŒ–æµ‹è¯•
- æä¾›å®æ—¶ç»Ÿè®¡å’Œæ±‡æ€»æŠ¥å‘Š

### æ ¸å¿ƒåŠŸèƒ½

1. **æµå¼å“åº”å¤„ç†**ï¼šå¤„ç† SSEï¼ˆServer-Sent Eventsï¼‰æ ¼å¼çš„æµå¼å“åº”
2. **æ€§èƒ½æŒ‡æ ‡è®¡ç®—**ï¼šè®¡ç®— TTFTã€TPOTã€ååé‡ç­‰å…³é”®æŒ‡æ ‡
3. **å¹¶å‘æµ‹è¯•**ï¼šæ”¯æŒå¤šçº¿ç¨‹å¹¶å‘å‹æµ‹
4. **å‚æ•°åŒ–æ”¯æŒ**ï¼šæ”¯æŒä»æ–‡ä»¶è¯»å–æŸ¥è¯¢å’Œ API Key
5. **å®æ—¶ç»Ÿè®¡**ï¼šæ¯ç§’æ±‡æ€»æ‰€æœ‰çº¿ç¨‹çš„ç»Ÿè®¡æ•°æ®
6. **ç»“æœæŠ¥å‘Š**ï¼šç”Ÿæˆè¯¦ç»†çš„æµ‹è¯•æŠ¥å‘Š

---

## æŠ€æœ¯æ ˆé€‰æ‹©

### Python 3.x

é€‰æ‹© Python çš„åŸå› ï¼š
- ä¸°å¯Œçš„ HTTP åº“ï¼ˆrequestsï¼‰
- å¼ºå¤§çš„å¹¶å‘æ”¯æŒï¼ˆthreadingï¼‰
- ç®€æ´çš„è¯­æ³•ï¼Œæ˜“äºç»´æŠ¤
- ä¸°å¯Œçš„ç¬¬ä¸‰æ–¹åº“ç”Ÿæ€

### æ ¸å¿ƒä¾èµ–

```python
import json          # JSON æ•°æ®å¤„ç†
import time          # æ—¶é—´æˆ³å’Œå»¶æ—¶
import sys           # ç³»ç»Ÿç›¸å…³
import argparse      # å‘½ä»¤è¡Œå‚æ•°è§£æ
import threading     # å¤šçº¿ç¨‹æ”¯æŒ
from datetime import datetime  # æ—¶é—´æ ¼å¼åŒ–
from typing import Dict, List, Optional, Any  # ç±»å‹æç¤º
from collections import deque  # åŒç«¯é˜Ÿåˆ—ï¼ˆç”¨äºå¾ªç¯ï¼‰
import requests      # HTTP è¯·æ±‚åº“
from requests.adapters import HTTPAdapter  # è¯·æ±‚é€‚é…å™¨
from urllib3.util.retry import Retry  # é‡è¯•ç­–ç•¥
```

### ä¾èµ–å®‰è£…

åˆ›å»º `requirements.txt`ï¼š

```txt
requests>=2.28.0
urllib3>=1.26.0
```

å®‰è£…å‘½ä»¤ï¼š

```bash
pip3 install -r requirements.txt
```

---

## æ¶æ„è®¾è®¡

### æ•´ä½“æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              å‘½ä»¤è¡Œæ¥å£å±‚                        â”‚
â”‚         (argparse å‚æ•°è§£æ)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              æ ¸å¿ƒæµ‹è¯•å¼•æ“                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚ QueryProviderâ”‚  â”‚ApiKeyProviderâ”‚            â”‚
â”‚  â”‚ (æŸ¥è¯¢æä¾›å™¨) â”‚  â”‚ (Keyæä¾›å™¨)  â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚      SSETester (æµ‹è¯•å™¨)               â”‚     â”‚
â”‚  â”‚  - å‘é€è¯·æ±‚                           â”‚     â”‚
â”‚  â”‚  - å¤„ç†æµå¼å“åº”                       â”‚     â”‚
â”‚  â”‚  - è®¡ç®—æ€§èƒ½æŒ‡æ ‡                       â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              å¹¶å‘æ§åˆ¶å±‚                          â”‚
â”‚  - çº¿ç¨‹ç®¡ç†                                     â”‚
â”‚  - Ramp-up æ§åˆ¶                                 â”‚
â”‚  - Duration æ§åˆ¶                                â”‚
â”‚  - å…±äº«ç»Ÿè®¡ä¿¡æ¯                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              ç»Ÿè®¡æ±‡æ€»å±‚                          â”‚
â”‚  - å®æ—¶æ±‡æ€»çº¿ç¨‹                                  â”‚
â”‚  - æœ€ç»ˆæŠ¥å‘Šç”Ÿæˆ                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### æ ¸å¿ƒç±»è®¾è®¡

1. **QueryProvider**ï¼šçº¿ç¨‹å®‰å…¨çš„æŸ¥è¯¢æä¾›å™¨
2. **ApiKeyProvider**ï¼šçº¿ç¨‹å®‰å…¨çš„ API Key æä¾›å™¨
3. **SSETester**ï¼šæ ¸å¿ƒæµ‹è¯•å™¨ç±»
4. **run_test_thread**ï¼šçº¿ç¨‹æ‰§è¡Œå‡½æ•°
5. **aggregate_stats**ï¼šç»Ÿè®¡æ±‡æ€»å‡½æ•°

---

## é€æ­¥å®ç°

### ç¬¬ä¸€æ­¥ï¼šé¡¹ç›®åˆå§‹åŒ–

åˆ›å»ºé¡¹ç›®ç»“æ„ï¼š

```bash
mkdir ai_loadtest_tool
cd ai_loadtest_tool
touch test_ai_streaming.py
touch requirements.txt
touch README.md
```

ç¼–å†™ `requirements.txt`ï¼š

```txt
requests>=2.28.0
urllib3>=1.26.0
```

### ç¬¬äºŒæ­¥ï¼šåŸºç¡€æ¡†æ¶æ­å»º

#### 2.1 å¯¼å…¥å¿…è¦çš„åº“

```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AI å¤§æ¨¡å‹æµå¼è¾“å‡ºæ€§èƒ½æµ‹è¯•å·¥å…·
"""

import json
import time
import sys
import argparse
import threading
from datetime import datetime
from typing import Dict, List, Optional, Any
from collections import deque
import requests
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
```

#### 2.2 åˆ›å»ºåŸºç¡€æµ‹è¯•å™¨ç±»

```python
class AITester:
    """AI æµå¼è¾“å‡ºæµ‹è¯•å™¨åŸºç±»"""
    
    def __init__(self, host: str = "localhost", port: int = 80, 
                 api_key: str = "", timeout: int = 60):
        self.host = host
        self.port = port
        self.api_key = api_key
        self.timeout = timeout
        self.base_url = f"http://{host}:{port}"
        
        # åˆ›å»ºå¸¦é‡è¯•æœºåˆ¶çš„ session
        self.session = requests.Session()
        retry_strategy = Retry(
            total=3,
            backoff_factor=0.1,
            status_forcelist=[429, 500, 502, 503, 504],
        )
        adapter = HTTPAdapter(max_retries=retry_strategy)
        self.session.mount("http://", adapter)
        self.session.mount("https://", adapter)
```

**å…³é”®ç‚¹**ï¼š
- ä½¿ç”¨ `requests.Session()` å¤ç”¨è¿æ¥ï¼Œæé«˜æ€§èƒ½
- é…ç½®é‡è¯•ç­–ç•¥ï¼Œè‡ªåŠ¨å¤„ç†ä¸´æ—¶é”™è¯¯
- æ”¯æŒ HTTP å’Œ HTTPS

### ç¬¬ä¸‰æ­¥ï¼šå®ç°æµå¼å“åº”å¤„ç†

#### 3.1 å‘é€æµå¼è¯·æ±‚

```python
def test_streaming(self, query: str, verbose: bool = True) -> Dict:
    """æµ‹è¯•æµå¼è¾“å‡º"""
    
    # æ„å»ºè¯·æ±‚ URL
    url = f"{self.base_url}/v1/chat-messages"
    
    # æ„å»ºè¯·æ±‚ä½“
    request_body = {
        "query": query,
        "response_mode": "streaming",
        # ... å…¶ä»–å‚æ•°
    }
    
    # è®¾ç½®è¯·æ±‚å¤´
    headers = {
        "Authorization": f"Bearer {self.api_key}",
        "Content-Type": "application/json",
        "Accept": "text/event-stream"
    }
    
    # åˆå§‹åŒ–ç»Ÿè®¡å˜é‡
    stats = {
        "request_start_time": 0,
        "first_byte_time": 0,
        "first_token_time": 0,
        "chunk_count": 0,
        "token_count": 0,
        "full_answer": "",
        "error": None
    }
    
    try:
        # è®°å½•è¯·æ±‚å¼€å§‹æ—¶é—´
        stats["request_start_time"] = time.time() * 1000
        
        # å‘é€ POST è¯·æ±‚ï¼Œå¯ç”¨æµå¼å“åº”
        response = self.session.post(
            url,
            json=request_body,
            headers=headers,
            stream=True,  # å…³é”®ï¼šå¯ç”¨æµå¼å“åº”
            timeout=self.timeout
        )
        
        # æ£€æŸ¥å“åº”çŠ¶æ€
        if response.status_code != 200:
            stats["error"] = f"HTTP {response.status_code}"
            return stats
        
        # å¤„ç†æµå¼å“åº”
        # ...
        
    except Exception as e:
        stats["error"] = str(e)
        return stats
```

**å…³é”®ç‚¹**ï¼š
- `stream=True`ï¼šå¯ç”¨æµå¼å“åº”ï¼Œä¸ä¼šä¸€æ¬¡æ€§åŠ è½½æ‰€æœ‰å†…å®¹
- ä½¿ç”¨æ¯«ç§’çº§æ—¶é—´æˆ³ï¼Œæé«˜ç²¾åº¦
- å®Œå–„çš„é”™è¯¯å¤„ç†

#### 3.2 è§£æ SSE æ ¼å¼å“åº”

```python
# è¯»å–æµå¼å“åº”
first_byte_received = False
first_token_received = False

for line in response.iter_lines(decode_unicode=True):
    if line is None:
        continue
    
    # è®°å½•é¦–å­—èŠ‚æ—¶é—´
    if not first_byte_received:
        stats["first_byte_time"] = time.time() * 1000
        first_byte_received = True
    
    # å¤„ç† Server-Sent Events (SSE) æ ¼å¼
    if line.startswith("data: "):
        data = line[6:]  # å»æ‰ "data: " å‰ç¼€
        
        # è·³è¿‡ç©ºæ•°æ®æˆ–ç»“æŸæ ‡è®°
        if not data.strip() or data.strip() == "[DONE]":
            continue
        
        try:
            # è§£æ JSON æ•°æ®
            json_data = json.loads(data)
            
            # æå–æµå¼æ–‡æœ¬æ•°æ®
            if "answer" in json_data:
                answer_chunk = json_data["answer"]
                
                # è®°å½•ç¬¬ä¸€ä¸ª token çš„æ—¶é—´ï¼ˆTTFTï¼‰
                if not first_token_received:
                    stats["first_token_time"] = time.time() * 1000
                    first_token_received = True
                
                # æ›´æ–°ç»Ÿè®¡
                stats["full_answer"] += answer_chunk
                stats["chunk_count"] += 1
                
        except json.JSONDecodeError:
            # å¤„ç†è§£æé”™è¯¯
            pass
```

**å…³é”®ç‚¹**ï¼š
- `iter_lines(decode_unicode=True)`ï¼šé€è¡Œè¯»å–ï¼Œè‡ªåŠ¨è§£ç  Unicode
- SSE æ ¼å¼ï¼š`data: {...}` å‰ç¼€
- å®æ—¶å¤„ç†ï¼šæ¯æ”¶åˆ°ä¸€ä¸ªæ•°æ®å—ç«‹å³å¤„ç†

### ç¬¬å››æ­¥ï¼šå®ç°æ€§èƒ½æŒ‡æ ‡è®¡ç®—

#### 4.1 Token æ•°é‡ä¼°ç®—

```python
def _estimate_tokens(self, text: str) -> int:
    """
    ä¼°ç®—æ–‡æœ¬çš„ token æ•°é‡
    ç®€å•ä¼°ç®—ï¼šä¸­æ–‡å­—ç¬¦ç®—1ä¸ªtokenï¼Œè‹±æ–‡å•è¯ç®—1ä¸ªtoken
    """
    # ä¸­æ–‡å­—ç¬¦æ•°
    chinese_chars = sum(1 for c in text if '\u4e00' <= c <= '\u9fff')
    
    # è‹±æ–‡å•è¯æ•°
    english_words = len([w for w in text.split() if w.isalpha()])
    
    # è‡³å°‘ç®—1ä¸ªtoken
    return max(1, chinese_chars + english_words)
```

**è¯´æ˜**ï¼š
- è¿™æ˜¯ç®€åŒ–ä¼°ç®—ï¼Œå®é™…é¡¹ç›®ä¸­å¯ä»¥ä½¿ç”¨ tiktoken ç­‰åº“
- å¯¹äºç²¾ç¡®æµ‹è¯•ï¼Œå»ºè®®ä½¿ç”¨å®é™…çš„ tokenizer

#### 4.2 è®¡ç®—å…³é”®æŒ‡æ ‡

```python
def _calculate_metrics(self, stats: Dict):
    """è®¡ç®—å…³é”®æ€§èƒ½æŒ‡æ ‡"""
    
    # 1. TTFB (Time To First Byte)
    stats["ttfb"] = stats["first_byte_time"] - stats["request_start_time"]
    
    # 2. TTFT (Time To First Token)
    if stats["first_token_time"] > 0:
        stats["ttft"] = stats["first_token_time"] - stats["request_start_time"]
    else:
        stats["ttft"] = 0
    
    # 3. TPOT (Time Per Output Token)
    # éœ€è¦è®°å½•æ¯ä¸ª token çš„æ—¶é—´æˆ³
    if stats["token_count"] > 1 and len(stats["token_times"]) > 1:
        first_token_time = stats["token_times"][0]
        last_token_time = stats["token_times"][-1]
        total_token_time = last_token_time - first_token_time
        stats["tpot"] = total_token_time / (stats["token_count"] - 1)
    else:
        stats["tpot"] = 0
    
    # 4. ååé‡ (Tokens/s)
    if stats["streaming_duration"] > 0 and stats["token_count"] > 0:
        stats["throughput"] = (stats["token_count"] / stats["streaming_duration"]) * 1000
    else:
        stats["throughput"] = 0
```

**å…³é”®æŒ‡æ ‡è¯´æ˜**ï¼š

1. **TTFB (Time To First Byte)**
   - ä»è¯·æ±‚å¼€å§‹åˆ°æ”¶åˆ°ç¬¬ä¸€ä¸ªå­—èŠ‚çš„æ—¶é—´
   - åæ˜ ç½‘ç»œå»¶è¿Ÿå’ŒæœåŠ¡å™¨åˆå§‹å“åº”é€Ÿåº¦

2. **TTFT (Time To First Token)**
   - ä»è¯·æ±‚å¼€å§‹åˆ°æ”¶åˆ°ç¬¬ä¸€ä¸ªæœ‰æ•ˆ token çš„æ—¶é—´
   - AI æ¨¡å‹æ€§èƒ½çš„å…³é”®æŒ‡æ ‡

3. **TPOT (Time Per Output Token)**
   - æ¯ä¸ªè¾“å‡º token çš„å¹³å‡æ—¶é—´
   - åæ˜ æ¨¡å‹çš„ç”Ÿæˆé€Ÿåº¦

4. **ååé‡ (Throughput)**
   - æ¯ç§’è¾“å‡ºçš„ token æ•°é‡
   - åæ˜ æ•´ä½“æ€§èƒ½

### ç¬¬äº”æ­¥ï¼šå®ç°çº¿ç¨‹å®‰å…¨çš„å‚æ•°åŒ–æä¾›å™¨

#### 5.1 QueryProvider å®ç°

```python
class QueryProvider:
    """å‚æ•°åŒ–æŸ¥è¯¢æä¾›å™¨ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰"""
    
    def __init__(self, param_file: Optional[str] = None, default_query: str = "ä½ å¥½"):
        self.lock = threading.Lock()  # çº¿ç¨‹é”
        self.queries = deque()        # ä½¿ç”¨åŒç«¯é˜Ÿåˆ—
        self.current_index = 0
        
        # ä»æ–‡ä»¶è¯»å–æŸ¥è¯¢
        if param_file:
            try:
                with open(param_file, 'r', encoding='utf-8') as f:
                    for line in f:
                        query = line.strip()
                        if query:  # è·³è¿‡ç©ºè¡Œ
                            self.queries.append(query)
            except Exception as e:
                print(f"è­¦å‘Š: è¯»å–å‚æ•°åŒ–æ–‡ä»¶å¤±è´¥: {e}")
                self.queries.append(default_query)
        else:
            self.queries.append(default_query)
    
    def get_next_query(self) -> str:
        """è·å–ä¸‹ä¸€ä¸ªæŸ¥è¯¢ï¼ˆçº¿ç¨‹å®‰å…¨ï¼Œå¾ªç¯è½®è¯¢ï¼‰"""
        with self.lock:  # ä½¿ç”¨é”ä¿è¯çº¿ç¨‹å®‰å…¨
            if not self.queries:
                return "ä½ å¥½"
            
            query = self.queries[self.current_index]
            self.current_index = (self.current_index + 1) % len(self.queries)  # å¾ªç¯
            return query
```

**å…³é”®ç‚¹**ï¼š
- `threading.Lock()`ï¼šä¿è¯å¤šçº¿ç¨‹å®‰å…¨
- `deque`ï¼šé«˜æ•ˆçš„åŒç«¯é˜Ÿåˆ—
- å¾ªç¯è½®è¯¢ï¼šä½¿ç”¨å–æ¨¡è¿ç®—å®ç°å¾ªç¯

#### 5.2 ApiKeyProvider å®ç°

```python
class ApiKeyProvider:
    """API Key æä¾›å™¨ï¼ˆçº¿ç¨‹å®‰å…¨ï¼Œå¾ªç¯ä½¿ç”¨ï¼‰"""
    
    def __init__(self, key_file: Optional[str] = None, default_key: str = ""):
        self.lock = threading.Lock()
        self.keys = deque()
        self.current_index = 0
        
        if key_file:
            try:
                with open(key_file, "r", encoding="utf-8") as f:
                    for line in f:
                        k = line.strip()
                        if k:
                            self.keys.append(k)
            except Exception as e:
                print(f"è­¦å‘Š: è¯»å– API Key æ–‡ä»¶å¤±è´¥: {e}")
                if default_key:
                    self.keys.append(default_key)
        
        if not self.keys and default_key:
            self.keys.append(default_key)
    
    def get_next_key(self) -> str:
        """è·å–ä¸‹ä¸€ä¸ª API Keyï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰"""
        with self.lock:
            if not self.keys:
                return ""
            key = self.keys[self.current_index]
            self.current_index = (self.current_index + 1) % len(self.keys)
            return key
```

### ç¬¬å…­æ­¥ï¼šå®ç°å¤šçº¿ç¨‹å¹¶å‘æµ‹è¯•

#### 6.1 çº¿ç¨‹æ‰§è¡Œå‡½æ•°

```python
def run_test_thread(tester: AITester, query_provider: QueryProvider,
                    thread_id: int, results_list: List[Dict], 
                    results_lock: threading.Lock,
                    shared_stats: Optional[Dict[str, Any]] = None,
                    stop_event: Optional[threading.Event] = None,
                    end_time_ms: Optional[float] = None):
    """è¿è¡Œæµ‹è¯•çš„çº¿ç¨‹å‡½æ•°"""
    
    # åˆå§‹åŒ–çº¿ç¨‹ç»Ÿè®¡
    if shared_stats is not None:
        with shared_stats["lock"]:
            shared_stats["thread_stats"][thread_id] = {
                "start_time": time.time() * 1000,
                "chunks": 0,
                "tokens": 0,
                "last_update": time.time() * 1000
            }
    
    # å¾ªç¯æ‰§è¡Œæµ‹è¯•ï¼ˆå¦‚æœè®¾ç½®äº† durationï¼‰
    def time_remaining_ok() -> bool:
        if stop_event and stop_event.is_set():
            return False
        if end_time_ms is not None:
            return time.time() * 1000 < end_time_ms
        return True
    
    while time_remaining_ok():
        # è·å–æŸ¥è¯¢
        query = query_provider.get_next_query()
        
        # æ‰§è¡Œæµ‹è¯•
        result = tester.test_streaming(
            query=query,
            verbose=False,  # å¤šçº¿ç¨‹æ—¶å…³é—­è¯¦ç»†è¾“å‡º
            thread_id=thread_id,
            shared_stats=shared_stats
        )
        
        # ä¿å­˜ç»“æœ
        result["thread_id"] = thread_id
        with results_lock:
            results_list.append(result)
        
        # æ›´æ–°å…±äº«ç»Ÿè®¡
        if shared_stats is not None:
            with shared_stats["lock"]:
                shared_stats["requests"] += 1
                if not result.get("error"):
                    shared_stats["success"] += 1
                else:
                    shared_stats["fail"] += 1
        
        # å¦‚æœåªè·‘ä¸€æ¬¡ï¼Œé€€å‡ºå¾ªç¯
        if end_time_ms is None and stop_event is None:
            break
```

**å…³é”®ç‚¹**ï¼š
- ä½¿ç”¨ `threading.Event` æ§åˆ¶çº¿ç¨‹åœæ­¢
- ä½¿ç”¨ `threading.Lock` ä¿æŠ¤å…±äº«æ•°æ®
- æ”¯æŒå¾ªç¯æ‰§è¡Œï¼ˆduration æ¨¡å¼ï¼‰

#### 6.2 ä¸»å‡½æ•°ä¸­çš„çº¿ç¨‹ç®¡ç†

```python
def main():
    parser = argparse.ArgumentParser(description="AI æµå¼è¾“å‡ºæ€§èƒ½æµ‹è¯•å·¥å…·")
    parser.add_argument("--threads", type=int, default=1, help="å¹¶å‘çº¿ç¨‹æ•°")
    parser.add_argument("--ramp-up", type=int, default=0, help="çº¿ç¨‹é€’å¢æ—¶é—´ï¼ˆç§’ï¼‰")
    parser.add_argument("--duration", type=int, default=0, help="æµ‹è¯•æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰")
    # ... å…¶ä»–å‚æ•°
    
    args = parser.parse_args()
    
    # åˆ›å»ºæµ‹è¯•å™¨
    tester = AITester(host=args.host, port=args.port, api_key=args.api_key)
    
    # åˆ›å»ºæŸ¥è¯¢æä¾›å™¨
    query_provider = QueryProvider(param_file=args.param_file)
    
    # åˆå§‹åŒ–å…±äº«ç»Ÿè®¡
    shared_stats = {
        "lock": threading.Lock(),
        "thread_stats": {},
        "start_time": time.time() * 1000,
        "total_threads": args.threads,
        "requests": 0,
        "success": 0,
        "fail": 0
    }
    
    # åˆ›å»ºåœæ­¢äº‹ä»¶å’ŒæŒç»­æ—¶é—´æ§åˆ¶
    stop_event = threading.Event()
    duration_ms = args.duration * 1000 if args.duration > 0 else None
    end_time_ms = shared_stats["start_time"] + duration_ms if duration_ms else None
    
    # å¯åŠ¨æ±‡æ€»çº¿ç¨‹
    results_list = []
    results_lock = threading.Lock()
    
    # åˆ›å»ºå¹¶å¯åŠ¨æµ‹è¯•çº¿ç¨‹
    threads = []
    for i in range(args.threads):
        # Ramp-up æ§åˆ¶ï¼šé€æ­¥å¯åŠ¨çº¿ç¨‹
        if args.ramp_up > 0 and i > 0:
            ramp_step = args.ramp_up / args.threads
            time.sleep(ramp_step)
        
        thread = threading.Thread(
            target=run_test_thread,
            args=(tester, query_provider, i + 1, results_list, 
                  results_lock, shared_stats, stop_event, end_time_ms)
        )
        threads.append(thread)
        thread.start()
    
    # æŒç»­æ—¶é—´æ§åˆ¶ï¼šåˆ°è¾¾æ—¶é—´åè§¦å‘åœæ­¢
    if duration_ms:
        def timer_stop():
            time.sleep(args.duration)
            stop_event.set()
        timer_thread = threading.Thread(target=timer_stop, daemon=True)
        timer_thread.start()
    
    # ç­‰å¾…æ‰€æœ‰çº¿ç¨‹å®Œæˆ
    for thread in threads:
        thread.join()
    
    # è¾“å‡ºæœ€ç»ˆç»Ÿè®¡
    print_final_stats(results_list, args.threads, args.duration)
```

**å…³é”®ç‚¹**ï¼š
- Ramp-upï¼šé€šè¿‡ `time.sleep()` æ§åˆ¶çº¿ç¨‹å¯åŠ¨é—´éš”
- Durationï¼šä½¿ç”¨ç‹¬ç«‹çš„å®šæ—¶çº¿ç¨‹æ§åˆ¶æµ‹è¯•æ—¶é•¿
- çº¿ç¨‹åŒæ­¥ï¼šä½¿ç”¨ `join()` ç­‰å¾…æ‰€æœ‰çº¿ç¨‹å®Œæˆ

### ç¬¬ä¸ƒæ­¥ï¼šå®ç°å®æ—¶ç»Ÿè®¡æ±‡æ€»

#### 7.1 æ±‡æ€»ç»Ÿè®¡å‡½æ•°

```python
def aggregate_stats(shared_stats: Dict[str, Any], stop_event: threading.Event, 
                   verbose: bool = True):
    """æ¯ç§’æ±‡æ€»æ‰€æœ‰çº¿ç¨‹çš„å®æ—¶ç»Ÿè®¡ä¿¡æ¯"""
    
    printed_header = False
    header_line = "-" * 180
    
    while not stop_event.wait(1):  # æ¯ç§’æ‰§è¡Œä¸€æ¬¡
        if not verbose:
            continue
        
        with shared_stats["lock"]:
            thread_stats = list(shared_stats["thread_stats"].values())
            if not thread_stats:
                continue
            
            # è®¡ç®—æ±‡æ€»æ•°æ®
            active_threads = len(shared_stats["thread_stats"])
            total_threads = shared_stats.get("total_threads", active_threads)
            total_reqs = shared_stats.get("requests", 0)
            total_success = shared_stats.get("success", 0)
            
            # è®¡ç®—æ—¶é—´èŒƒå›´
            earliest_start = min(s.get("start_time", 0) for s in thread_stats)
            latest_update = max(s.get("last_update", 0) for s in thread_stats)
            
            # è®¡ç®—æ€»æ•°æ®
            total_chunks = sum(s.get("chunks", 0) for s in thread_stats)
            total_tokens = sum(s.get("tokens", 0) for s in thread_stats)
        
        # è®¡ç®—æŒ‡æ ‡
        elapsed_ms = max(latest_update - earliest_start, 1)
        avg_response_time = elapsed_ms / max(total_chunks, 1)
        tpot = elapsed_ms / max(total_tokens - 1, 1)
        tokens_per_second = (total_tokens * 1000) / elapsed_ms
        success_rate = (total_success / total_reqs * 100) if total_reqs > 0 else 0.0
        
        # è¾“å‡ºè¡¨æ ¼
        now_str = datetime.now().strftime("%H:%M:%S")
        if not printed_header:
            print("\n" + header_line)
            print(f"{'æ—¶é—´':<10} {'çº¿ç¨‹æ•°(æ´»è·ƒ/æ€»)':<18} {'æ•°æ®å—':>12} "
                  f"{'å¹³å‡å“åº”æ—¶é—´(ms)':>22} {'TPOT(ms/token)':>22} "
                  f"{'Tokens/s':>22} {'æˆåŠŸç‡(%)':>14}")
            print(header_line)
            printed_header = True
        
        print(f"{now_str:<10} {f'{active_threads}/{total_threads}':<18} "
              f"{total_chunks:>12} {avg_response_time:>22.2f} "
              f"{tpot:>22.2f} {tokens_per_second:>22.2f} {success_rate:>14.2f}")
```

**å…³é”®ç‚¹**ï¼š
- `stop_event.wait(1)`ï¼šæ¯ç§’å”¤é†’ä¸€æ¬¡ï¼Œæ£€æŸ¥åœæ­¢æ ‡å¿—
- çº¿ç¨‹å®‰å…¨ï¼šä½¿ç”¨é”ä¿æŠ¤å…±äº«æ•°æ®è®¿é—®
- å®æ—¶è®¡ç®—ï¼šæ¯æ¬¡å¾ªç¯é‡æ–°è®¡ç®—æ‰€æœ‰æŒ‡æ ‡

#### 7.2 åœ¨ä¸»å‡½æ•°ä¸­å¯åŠ¨æ±‡æ€»çº¿ç¨‹

```python
# å¯åŠ¨æ±‡æ€»çº¿ç¨‹
if enable_agg:
    agg_thread = threading.Thread(
        target=aggregate_stats, 
        args=(shared_stats, stop_event, not args.quiet), 
        daemon=True  # å®ˆæŠ¤çº¿ç¨‹ï¼Œä¸»ç¨‹åºé€€å‡ºæ—¶è‡ªåŠ¨ç»“æŸ
    )
    agg_thread.start()
```

### ç¬¬å…«æ­¥ï¼šå®ç°å‘½ä»¤è¡Œæ¥å£

#### 8.1 ä½¿ç”¨ argparse è§£æå‚æ•°

```python
def main():
    parser = argparse.ArgumentParser(
        description="AI æµå¼è¾“å‡ºæ€§èƒ½æµ‹è¯•å·¥å…·",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # åŸºæœ¬æµ‹è¯•
  python3 test_ai_streaming.py --host localhost --port 8080
  
  # å¤šçº¿ç¨‹æµ‹è¯•
  python3 test_ai_streaming.py --host localhost --port 8080 --threads 5
  
  # æŒç»­å‹æµ‹
  python3 test_ai_streaming.py --host localhost --port 8080 --threads 10 --ramp-up 10 --duration 60
        """
    )
    
    # åŸºç¡€å‚æ•°
    parser.add_argument("--host", type=str, default="localhost",
                       help="æœåŠ¡å™¨ä¸»æœºåœ°å€")
    parser.add_argument("--port", type=int, default=8080,
                       help="æœåŠ¡å™¨ç«¯å£")
    parser.add_argument("--api-key", type=str, default="",
                       help="API å¯†é’¥")
    
    # æµ‹è¯•å‚æ•°
    parser.add_argument("--threads", type=int, default=1,
                       help="å¹¶å‘çº¿ç¨‹æ•°")
    parser.add_argument("--ramp-up", type=int, default=0,
                       help="çº¿ç¨‹é€’å¢æ—¶é—´ï¼ˆç§’ï¼‰")
    parser.add_argument("--duration", type=int, default=0,
                       help="æµ‹è¯•æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰")
    
    # å‚æ•°åŒ–
    parser.add_argument("--param-file", type=str, default=None,
                       help="å‚æ•°åŒ–æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--api-key-file", type=str, default=None,
                       help="API Key å‚æ•°åŒ–æ–‡ä»¶è·¯å¾„")
    
    # å…¶ä»–
    parser.add_argument("--quiet", action="store_true",
                       help="é™é»˜æ¨¡å¼")
    
    args = parser.parse_args()
    
    # æ‰§è¡Œæµ‹è¯•
    # ...
```

**å…³é”®ç‚¹**ï¼š
- `argparse`ï¼šPython æ ‡å‡†åº“ï¼ŒåŠŸèƒ½å¼ºå¤§
- `action="store_true"`ï¼šå¸ƒå°”æ ‡å¿—å‚æ•°
- `formatter_class=RawDescriptionHelpFormatter`ï¼šä¿ç•™å¸®åŠ©æ–‡æœ¬æ ¼å¼

---

## å…³é”®æŠ€æœ¯è¯¦è§£

### 1. æµå¼å“åº”å¤„ç†

#### SSE (Server-Sent Events) æ ¼å¼

SSE æ˜¯ä¸€ç§æœåŠ¡å™¨æ¨é€æŠ€æœ¯ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š

```
data: {"answer": "ä½ å¥½"}

data: {"answer": "ï¼Œæˆ‘æ˜¯"}

data: {"answer": "AIåŠ©æ‰‹"}

data: [DONE]
```

**å¤„ç†è¦ç‚¹**ï¼š
- æ¯è¡Œä»¥ `data: ` å¼€å¤´
- ç©ºè¡Œæ˜¯åˆ†éš”ç¬¦
- `[DONE]` è¡¨ç¤ºç»“æŸ

#### é€è¡Œè¯»å–

```python
for line in response.iter_lines(decode_unicode=True):
    if line.startswith("data: "):
        data = line[6:]  # å»æ‰å‰ç¼€
        json_data = json.loads(data)  # è§£æ JSON
```

**å…³é”®**ï¼š
- `iter_lines()`ï¼šé€è¡Œè¿­ä»£ï¼Œä¸ä¸€æ¬¡æ€§åŠ è½½
- `decode_unicode=True`ï¼šè‡ªåŠ¨è§£ç  Unicode

### 2. çº¿ç¨‹å®‰å…¨è®¾è®¡

#### ä½¿ç”¨é”ä¿æŠ¤å…±äº«æ•°æ®

```python
class QueryProvider:
    def __init__(self):
        self.lock = threading.Lock()  # åˆ›å»ºé”
        self.queries = deque()
        self.current_index = 0
    
    def get_next_query(self):
        with self.lock:  # è·å–é”
            # ä¸´ç•ŒåŒºä»£ç 
            query = self.queries[self.current_index]
            self.current_index = (self.current_index + 1) % len(self.queries)
            return query
        # è‡ªåŠ¨é‡Šæ”¾é”
```

**å…³é”®ç‚¹**ï¼š
- `with self.lock`ï¼šè‡ªåŠ¨è·å–å’Œé‡Šæ”¾é”
- ä¸´ç•ŒåŒºå°½å¯èƒ½å°ï¼Œå‡å°‘é”ç«äº‰

#### å…±äº«ç»Ÿè®¡ä¿¡æ¯

```python
shared_stats = {
    "lock": threading.Lock(),
    "thread_stats": {},  # æ¯ä¸ªçº¿ç¨‹çš„ç»Ÿè®¡
    "requests": 0,        # æ€»è¯·æ±‚æ•°
    "success": 0,         # æˆåŠŸæ•°
    "fail": 0            # å¤±è´¥æ•°
}

# æ›´æ–°ç»Ÿè®¡
with shared_stats["lock"]:
    shared_stats["requests"] += 1
    if success:
        shared_stats["success"] += 1
```

### 3. æ—¶é—´æˆ³ç®¡ç†

#### ä½¿ç”¨æ¯«ç§’çº§æ—¶é—´æˆ³

```python
# è·å–å½“å‰æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
current_time = time.time() * 1000

# è®¡ç®—æ—¶é—´å·®
elapsed_ms = end_time - start_time
```

**åŸå› **ï¼š
- æ¯«ç§’çº§ç²¾åº¦è¶³å¤Ÿï¼Œä¸”è®¡ç®—ç®€å•
- é¿å…æµ®ç‚¹æ•°ç²¾åº¦é—®é¢˜

#### è®°å½•å…³é”®æ—¶é—´ç‚¹

```python
stats = {
    "request_start_time": time.time() * 1000,  # è¯·æ±‚å¼€å§‹
    "first_byte_time": 0,                      # é¦–å­—èŠ‚
    "first_token_time": 0,                     # é¦–Token
    "last_byte_time": 0,                      # æœ€åå­—èŠ‚
    "request_end_time": 0                     # è¯·æ±‚ç»“æŸ
}
```

### 4. Token è®¡æ•°ç­–ç•¥

#### ç®€å•ä¼°ç®—æ–¹æ³•

```python
def _estimate_tokens(self, text: str) -> int:
    # ä¸­æ–‡å­—ç¬¦æ•°
    chinese_chars = sum(1 for c in text if '\u4e00' <= c <= '\u9fff')
    
    # è‹±æ–‡å•è¯æ•°
    english_words = len([w for w in text.split() if w.isalpha()])
    
    return max(1, chinese_chars + english_words)
```

#### ç²¾ç¡®è®¡æ•°æ–¹æ³•ï¼ˆå¯é€‰ï¼‰

```python
# ä½¿ç”¨ tiktokenï¼ˆéœ€è¦å®‰è£…ï¼špip install tiktokenï¼‰
import tiktoken

def _estimate_tokens(self, text: str, model: str = "gpt-3.5-turbo") -> int:
    encoding = tiktoken.encoding_for_model(model)
    return len(encoding.encode(text))
```

### 5. é”™è¯¯å¤„ç†ç­–ç•¥

#### åˆ†å±‚é”™è¯¯å¤„ç†

```python
try:
    # å‘é€è¯·æ±‚
    response = self.session.post(url, json=request_body, stream=True)
    
    # æ£€æŸ¥ HTTP çŠ¶æ€ç 
    if response.status_code != 200:
        stats["error"] = f"HTTP {response.status_code}"
        return stats
    
    # å¤„ç†å“åº”
    for line in response.iter_lines():
        try:
            # è§£æ JSON
            json_data = json.loads(data)
        except json.JSONDecodeError as e:
            # JSON è§£æé”™è¯¯ï¼Œè®°å½•ä½†ç»§ç»­
            if verbose:
                print(f"JSONè§£æé”™è¯¯: {e}")
            continue
            
except requests.exceptions.RequestException as e:
    # ç½‘ç»œé”™è¯¯
    stats["error"] = str(e)
    return stats
except Exception as e:
    # å…¶ä»–æœªçŸ¥é”™è¯¯
    stats["error"] = f"æœªçŸ¥é”™è¯¯: {e}"
    return stats
```

### 6. æ€§èƒ½ä¼˜åŒ–æŠ€å·§

#### è¿æ¥å¤ç”¨

```python
# ä½¿ç”¨ Session å¤ç”¨è¿æ¥
self.session = requests.Session()
# æ‰€æœ‰è¯·æ±‚ä½¿ç”¨åŒä¸€ä¸ª sessionï¼Œè‡ªåŠ¨å¤ç”¨ TCP è¿æ¥
```

#### æµå¼è¯»å–

```python
# ä½¿ç”¨ stream=Trueï¼Œä¸ä¸€æ¬¡æ€§åŠ è½½å“åº”
response = requests.post(url, stream=True)
for line in response.iter_lines():
    # é€è¡Œå¤„ç†ï¼Œå†…å­˜å ç”¨å°
```

#### å¼‚æ­¥å¤„ç†ï¼ˆé«˜çº§ï¼‰

```python
# ä½¿ç”¨ asyncio å’Œ aiohttpï¼ˆéœ€è¦é¢å¤–å®ç°ï¼‰
import asyncio
import aiohttp

async def test_streaming_async(session, url, data):
    async with session.post(url, json=data) as response:
        async for line in response.content:
            # å¤„ç†æµå¼æ•°æ®
            pass
```

---

## æµ‹è¯•ä¸ä¼˜åŒ–

### å•å…ƒæµ‹è¯•

åˆ›å»º `test_ai_tester.py`ï¼š

```python
import unittest
from test_ai_streaming import AITester, QueryProvider

class TestAITester(unittest.TestCase):
    def test_query_provider(self):
        provider = QueryProvider(default_query="test")
        self.assertEqual(provider.get_next_query(), "test")
    
    def test_token_estimation(self):
        tester = AITester()
        tokens = tester._estimate_tokens("ä½ å¥½ world")
        self.assertGreater(tokens, 0)

if __name__ == "__main__":
    unittest.main()
```

### æ€§èƒ½æµ‹è¯•

```bash
# æµ‹è¯•å•çº¿ç¨‹æ€§èƒ½
python3 test_ai_streaming.py --threads 1 --duration 10

# æµ‹è¯•å¤šçº¿ç¨‹æ€§èƒ½
python3 test_ai_streaming.py --threads 10 --duration 30

# æµ‹è¯•é«˜å¹¶å‘
python3 test_ai_streaming.py --threads 50 --ramp-up 20 --duration 60
```

### è°ƒè¯•æŠ€å·§

#### 1. å¯ç”¨è¯¦ç»†è¾“å‡º

```python
# åœ¨æµ‹è¯•å‡½æ•°ä¸­æ·»åŠ è°ƒè¯•è¾“å‡º
if verbose:
    print(f"[è°ƒè¯•] æ”¶åˆ°æ•°æ®: {data[:100]}")
    print(f"[è°ƒè¯•] è§£æç»“æœ: {json_data}")
```

#### 2. è®°å½•åŸå§‹å“åº”

```python
raw_lines = []
for line in response.iter_lines():
    if len(raw_lines) < 5:  # åªè®°å½•å‰5è¡Œ
        raw_lines.append(line)
    
# å¦‚æœæ²¡æœ‰æ”¶åˆ°æ•°æ®ï¼Œè¾“å‡ºåŸå§‹å“åº”
if chunk_count == 0:
    print("åŸå§‹å“åº”:")
    for line in raw_lines:
        print(f"  {line}")
```

#### 3. ä½¿ç”¨æ—¥å¿—æ¨¡å—

```python
import logging

logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger(__name__)

logger.debug(f"æ”¶åˆ°æ•°æ®å—: {chunk}")
logger.error(f"è¯·æ±‚å¤±è´¥: {error}")
```

---

## æ‰©å±•åŠŸèƒ½

### 1. ç»“æœå¯¼å‡ºï¼ˆCSV/JSONï¼‰

```python
import csv
import json

def export_results_csv(results_list: List[Dict], filename: str):
    """å¯¼å‡ºç»“æœä¸º CSV"""
    with open(filename, 'w', newline='', encoding='utf-8') as f:
        writer = csv.DictWriter(f, fieldnames=[
            'thread_id', 'query', 'chunk_count', 'token_count',
            'ttft', 'tpot', 'throughput', 'success'
        ])
        writer.writeheader()
        for result in results_list:
            writer.writerow(result)

def export_results_json(results_list: List[Dict], filename: str):
    """å¯¼å‡ºç»“æœä¸º JSON"""
    with open(filename, 'w', encoding='utf-8') as f:
        json.dump(results_list, f, ensure_ascii=False, indent=2)
```

### 2. å®æ—¶å›¾è¡¨ï¼ˆä½¿ç”¨ matplotlibï¼‰

```python
import matplotlib.pyplot as plt
from collections import deque

class RealTimePlotter:
    def __init__(self):
        self.times = deque(maxlen=100)
        self.throughputs = deque(maxlen=100)
        plt.ion()  # äº¤äº’æ¨¡å¼
    
    def update(self, throughput: float):
        self.times.append(time.time())
        self.throughputs.append(throughput)
        
        plt.clf()
        plt.plot(list(self.times), list(self.throughputs))
        plt.ylabel('Tokens/s')
        plt.xlabel('Time')
        plt.draw()
        plt.pause(0.01)
```

### 3. åˆ†å¸ƒå¼æµ‹è¯•ï¼ˆä½¿ç”¨å¤šè¿›ç¨‹ï¼‰

```python
from multiprocessing import Process, Queue

def run_test_process(queue: Queue, config: Dict):
    """åœ¨ç‹¬ç«‹è¿›ç¨‹ä¸­è¿è¡Œæµ‹è¯•"""
    tester = AITester(**config)
    results = tester.test_streaming(config['query'])
    queue.put(results)

# ä¸»è¿›ç¨‹
processes = []
for i in range(num_processes):
    p = Process(target=run_test_process, args=(queue, config))
    p.start()
    processes.append(p)
```

### 4. ç»“æœåˆ†ææŠ¥å‘Š

```python
def generate_report(results_list: List[Dict]) -> str:
    """ç”Ÿæˆ HTML æŠ¥å‘Š"""
    html = """
    <html>
    <head><title>æ€§èƒ½æµ‹è¯•æŠ¥å‘Š</title></head>
    <body>
        <h1>æ€§èƒ½æµ‹è¯•æŠ¥å‘Š</h1>
        <table>
            <tr>
                <th>æŒ‡æ ‡</th><th>å¹³å‡å€¼</th><th>æœ€å°å€¼</th><th>æœ€å¤§å€¼</th>
            </tr>
    """
    
    # è®¡ç®—ç»Ÿè®¡æ•°æ®
    ttfts = [r['ttft'] for r in results_list if r.get('ttft')]
    avg_ttft = sum(ttfts) / len(ttfts) if ttfts else 0
    
    html += f"""
            <tr>
                <td>TTFT</td>
                <td>{avg_ttft:.2f} ms</td>
                <td>{min(ttfts):.2f} ms</td>
                <td>{max(ttfts):.2f} ms</td>
            </tr>
    """
    
    html += """
        </table>
    </body>
    </html>
    """
    
    return html
```

---

## æœ€ä½³å®è·µ

### 1. ä»£ç ç»„ç»‡

```
ai_loadtest_tool/
â”œâ”€â”€ test_ai_streaming.py    # ä¸»æµ‹è¯•è„šæœ¬
â”œâ”€â”€ providers.py            # å‚æ•°åŒ–æä¾›å™¨
â”œâ”€â”€ metrics.py              # æŒ‡æ ‡è®¡ç®—
â”œâ”€â”€ utils.py                # å·¥å…·å‡½æ•°
â”œâ”€â”€ requirements.txt        # ä¾èµ–
â”œâ”€â”€ README.md              # æ–‡æ¡£
â””â”€â”€ tests/                 # æµ‹è¯•æ–‡ä»¶
    â””â”€â”€ test_providers.py
```

### 2. é…ç½®ç®¡ç†

```python
# config.py
class Config:
    DEFAULT_HOST = "localhost"
    DEFAULT_PORT = 8080
    DEFAULT_TIMEOUT = 60
    DEFAULT_THREADS = 1
    
    # å¯ä»¥ä»ç¯å¢ƒå˜é‡è¯»å–
    API_KEY = os.getenv("API_KEY", "")
```

### 3. æ—¥å¿—ç®¡ç†

```python
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('test.log'),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)
logger.info("æµ‹è¯•å¼€å§‹")
```

### 4. å¼‚å¸¸å¤„ç†

```python
# ä½¿ç”¨è£…é¥°å™¨ç»Ÿä¸€å¤„ç†å¼‚å¸¸
def handle_exceptions(func):
    def wrapper(*args, **kwargs):
        try:
            return func(*args, **kwargs)
        except Exception as e:
            logger.error(f"{func.__name__} å¤±è´¥: {e}", exc_info=True)
            return None
    return wrapper

@handle_exceptions
def test_streaming(self, query: str):
    # æµ‹è¯•é€»è¾‘
    pass
```

### 5. æ€§èƒ½ç›‘æ§

```python
import psutil
import time

def monitor_resources(duration: int):
    """ç›‘æ§ç³»ç»Ÿèµ„æºä½¿ç”¨"""
    start_time = time.time()
    cpu_samples = []
    memory_samples = []
    
    while time.time() - start_time < duration:
        cpu_samples.append(psutil.cpu_percent())
        memory_samples.append(psutil.virtual_memory().percent)
        time.sleep(1)
    
    print(f"å¹³å‡ CPU ä½¿ç”¨ç‡: {sum(cpu_samples)/len(cpu_samples):.2f}%")
    print(f"å¹³å‡å†…å­˜ä½¿ç”¨ç‡: {sum(memory_samples)/len(memory_samples):.2f}%")
```

---

## å®Œæ•´ç¤ºä¾‹ä»£ç ç»“æ„

### æœ€å°å¯ç”¨ç‰ˆæœ¬ï¼ˆMVPï¼‰

```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AI å¤§æ¨¡å‹æµå¼è¾“å‡ºæ€§èƒ½æµ‹è¯•å·¥å…· - æœ€å°ç‰ˆæœ¬
"""

import json
import time
import requests
import argparse

class SimpleAITester:
    def __init__(self, host: str, port: int, api_key: str):
        self.url = f"http://{host}:{port}/v1/chat-messages"
        self.api_key = api_key
    
    def test(self, query: str):
        """æ‰§è¡Œå•æ¬¡æµ‹è¯•"""
        stats = {
            "start_time": time.time() * 1000,
            "first_token_time": 0,
            "chunk_count": 0,
            "token_count": 0
        }
        
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json",
            "Accept": "text/event-stream"
        }
        
        body = {
            "query": query,
            "response_mode": "streaming"
        }
        
        try:
            response = requests.post(self.url, json=body, headers=headers, stream=True)
            
            if response.status_code != 200:
                print(f"é”™è¯¯: HTTP {response.status_code}")
                return stats
            
            first_token = True
            for line in response.iter_lines(decode_unicode=True):
                if line and line.startswith("data: "):
                    data = line[6:]
                    if data.strip() and data.strip() != "[DONE]":
                        try:
                            json_data = json.loads(data)
                            if "answer" in json_data:
                                if first_token:
                                    stats["first_token_time"] = time.time() * 1000
                                    first_token = False
                                stats["chunk_count"] += 1
                                stats["token_count"] += len(json_data["answer"])
                        except:
                            pass
            
            stats["end_time"] = time.time() * 1000
            stats["ttft"] = stats["first_token_time"] - stats["start_time"]
            stats["total_time"] = stats["end_time"] - stats["start_time"]
            
            return stats
            
        except Exception as e:
            print(f"é”™è¯¯: {e}")
            return stats

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--host", default="localhost")
    parser.add_argument("--port", type=int, default=80)
    parser.add_argument("--api-key", required=True)
    parser.add_argument("--query", default="ä½ å¥½")
    
    args = parser.parse_args()
    
    tester = SimpleAITester(args.host, args.port, args.api_key)
    result = tester.test(args.query)
    
    print(f"TTFT: {result['ttft']:.2f} ms")
    print(f"æ€»æ—¶é—´: {result['total_time']:.2f} ms")
    print(f"æ•°æ®å—æ•°: {result['chunk_count']}")
    print(f"Tokenæ•°: {result['token_count']}")

if __name__ == "__main__":
    main()
```

è¿™ä¸ªæœ€å°ç‰ˆæœ¬åŒ…å«ï¼š
- åŸºæœ¬çš„æµå¼è¯·æ±‚
- ç®€å•çš„ç»Ÿè®¡
- å‘½ä»¤è¡Œæ¥å£

å¯ä»¥åœ¨æ­¤åŸºç¡€ä¸Šé€æ­¥æ·»åŠ åŠŸèƒ½ã€‚

---

## æ€»ç»“

### å¼€å‘æµç¨‹

1. **éœ€æ±‚åˆ†æ** â†’ ç¡®å®šè¦æµ‹è¯•çš„æŒ‡æ ‡å’ŒåŠŸèƒ½
2. **æ¶æ„è®¾è®¡** â†’ è®¾è®¡ç±»ç»“æ„å’Œæ•°æ®æµ
3. **é€æ­¥å®ç°** â†’ ä»ç®€å•åˆ°å¤æ‚ï¼Œé€æ­¥æ·»åŠ åŠŸèƒ½
4. **æµ‹è¯•éªŒè¯** â†’ å•å…ƒæµ‹è¯•å’Œé›†æˆæµ‹è¯•
5. **ä¼˜åŒ–æ”¹è¿›** â†’ æ€§èƒ½ä¼˜åŒ–å’ŒåŠŸèƒ½æ‰©å±•

### å…³é”®è¦ç‚¹

1. **æµå¼å¤„ç†**ï¼šä½¿ç”¨ `stream=True` å’Œ `iter_lines()`
2. **çº¿ç¨‹å®‰å…¨**ï¼šä½¿ç”¨é”ä¿æŠ¤å…±äº«æ•°æ®
3. **æ—¶é—´ç®¡ç†**ï¼šä½¿ç”¨æ¯«ç§’çº§æ—¶é—´æˆ³
4. **é”™è¯¯å¤„ç†**ï¼šå®Œå–„çš„å¼‚å¸¸å¤„ç†æœºåˆ¶
5. **å¯æ‰©å±•æ€§**ï¼šæ¨¡å—åŒ–è®¾è®¡ï¼Œæ˜“äºæ‰©å±•

### ä¸‹ä¸€æ­¥

- æ·»åŠ æ›´å¤šæ€§èƒ½æŒ‡æ ‡
- æ”¯æŒæ›´å¤š API æ ¼å¼
- å®ç°ç»“æœå¯è§†åŒ–
- æ·»åŠ åˆ†å¸ƒå¼æµ‹è¯•æ”¯æŒ
- é›†æˆåˆ° CI/CD æµç¨‹

---

## å‚è€ƒèµ„æº

- [requests æ–‡æ¡£](https://requests.readthedocs.io/)
- [Python threading æ–‡æ¡£](https://docs.python.org/3/library/threading.html)
- [SSE è§„èŒƒ](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events)
- [æ€§èƒ½æµ‹è¯•æœ€ä½³å®è·µ](https://k6.io/docs/test-types/load-testing/)

---

**ç¥ä½ å¼€å‘é¡ºåˆ©ï¼** ğŸš€
